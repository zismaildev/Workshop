{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reciprocal Rank Fusion (RRF) Demo with MongoDB Atlas\n",
    "\n",
    "This notebook demonstrates how to implement **Reciprocal Rank Fusion (RRF)** to combine results from MongoDB Atlas **Full Text Search** and **Vector Search**.\n",
    "\n",
    "RRF is a method for combining multiple result sets with different scoring scales by using their **rank** positions instead of their raw scores. This is particularly useful when combining keyword search scores (BM25) with vector similarity scores (Cosine), as they have very different distributions.\n",
    "\n",
    "## Formula\n",
    "$$ RRFscore(d) = \\sum_{r \\in R} \\frac{1}{k + rank(d, r)} $$" ,
    "\n",
    "Where:\n",
    "*   $d$ is a document.\n",
    "*   $R$ is the set of rankers (e.g., Vector Search results, Keyword Search results).\n",
    "*   $rank(d, r)$ is the rank of document $d$ in result set $r$ (1-based).\n",
    "*   $k$ is a constant (typically 60) to smooth the impact of high rankings.\n",
    "\n",
    "## Prerequisites\n",
    "1.  **Data Loaded**: Ensure `mobile_reviews` collection is populated (see `b.mongodb_atlas_setup.ipynb`).\n",
    "2.  **Indexes**: \n",
    "    *   `vector_index` (Vector Search)\n",
    "    *   `default` (Full Text Search - see `c.rsf_demo.ipynb` to create this if missing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pymongo ollama pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import ollama\n",
    "import pandas as pd\n",
    "\n",
    "# --- CONFIGURATION --- \n",
    "# Replace with your actual connection string\n",
    "MONGODB_URI = \"<connection_string>\"\n",
    "DB_NAME = \"tech_on_the_rock\"\n",
    "COLLECTION_NAME = \"mobile_reviews\"\n",
    "\n",
    "# Connect\n",
    "client = pymongo.MongoClient(MONGODB_URI)\n",
    "db = client[DB_NAME]\n",
    "collection = db[COLLECTION_NAME]\n",
    "\n",
    "print(\"Connected to MongoDB Atlas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Search Functions\n",
    "\n",
    "We reuse the search functions for Vector and Keyword search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_embedding(query):\n",
    "    \"\"\"Generates vector embedding for the query using Ollama.\"\"\"\n",
    "    # Ensure you have 'qwen3-embedding' or the model you used for indexing available in Ollama\n",
    "    response = ollama.embeddings(model='qwen3-embedding', prompt=query)\n",
    "    return response['embedding']\n",
    "\n",
    "def search_vector(query, limit=20):\n",
    "    \"\"\"Performs Semantic Search using $vectorSearch.\"\"\"\n",
    "    query_vector = get_query_embedding(query)\n",
    "    \n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$vectorSearch\": {\n",
    "                \"index\": \"vector_index\",\n",
    "                \"path\": \"review_embedding\",\n",
    "                \"queryVector\": query_vector,\n",
    "                \"numCandidates\": limit * 10,\n",
    "                \"limit\": limit\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"_id\": 0,\n",
    "                \"review_id\": 1,\n",
    "                \"product_name\": 1,\n",
    "                \"review_text\": 1,\n",
    "                \"score\": { \"$meta\": \"vectorSearchScore\" }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    return list(collection.aggregate(pipeline))\n",
    "\n",
    "def search_keyword(query, limit=20):\n",
    "    \"\"\"Performs Keyword Search using $search.\"\"\"\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$search\": {\n",
    "                \"index\": \"default\",\n",
    "                \"text\": {\n",
    "                    \"query\": query,\n",
    "                    \"path\": [\"review_text\", \"product_name\", \"tags\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$limit\": limit\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"_id\": 0,\n",
    "                \"review_id\": 1,\n",
    "                \"product_name\": 1,\n",
    "                \"review_text\": 1,\n",
    "                \"score\": { \"$meta\": \"searchScore\" }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    return list(collection.aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implement Reciprocal Rank Fusion (RRF)\n",
    "\n",
    "The core RRF algorithm implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_rank_fusion(results_dict, k=60):\n",
    "    \"\"\"\n",
    "    Combines multiple lists of results using RRF.\n",
    "    \n",
    "    Args:\n",
    "        results_dict: Dictionary where key is the name of the ranker (e.g., 'vector', 'keyword') \n",
    "                      and value is the list of result documents.\n",
    "        k: Smoothing constant (default 60).\n",
    "        \n",
    "    Returns:\n",
    "        List of documents sorted by RRF score.\n",
    "    \"\"\"\n",
    "    fused_scores = {}\n",
    "    \n",
    "    for ranker_name, results in results_dict.items():\n",
    "        for rank, doc in enumerate(results):\n",
    "            # rank is 0-based in enumerate, RRF usually expects 1-based, or just consistent.\n",
    "            # Formula: 1 / (k + rank + 1)\n",
    "            \n",
    "            doc_id = doc['review_id']\n",
    "            \n",
    "            if doc_id not in fused_scores:\n",
    "                fused_scores[doc_id] = {\n",
    "                    \"doc\": doc,\n",
    "                    \"rrf_score\": 0,\n",
    "                    \"details\": {}\n",
    "                }\n",
    "            \n",
    "            # Calculate score contribution from this ranker\n",
    "            score = 1 / (k + rank + 1)\n",
    "            fused_scores[doc_id]['rrf_score'] += score\n",
    "            \n",
    "            # Store details for display\n",
    "            fused_scores[doc_id]['details'][ranker_name] = {\n",
    "                \"rank\": rank + 1,\n",
    "                \"raw_score\": doc['score']\n",
    "            }\n",
    "\n",
    "    # Convert to list\n",
    "    final_results = []\n",
    "    for doc_id, data in fused_scores.items():\n",
    "        item = data['doc'].copy()\n",
    "        del item['score'] # Remove the single raw score\n",
    "        item['rrf_score'] = data['rrf_score']\n",
    "        item['ranks'] = data['details']\n",
    "        final_results.append(item)\n",
    "    \n",
    "    # Sort by RRF score descending\n",
    "    return sorted(final_results, key=lambda x: x['rrf_score'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the Demo\n",
    "\n",
    "We search for **\"night photography\"** again to compare with RSF results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"night photography\"\n",
    "\n",
    "print(f\"--- Searching for: '{QUERY}' ---\")\n",
    "\n",
    "# 1. Fetch Results\n",
    "print(\"Running Vector Search...\")\n",
    "vec_results = search_vector(QUERY, limit=10)\n",
    "\n",
    "print(\"Running Keyword Search...\")\n",
    "kw_results = search_keyword(QUERY, limit=10)\n",
    "\n",
    "# 2. Apply RRF\n",
    "print(\"Applying Reciprocal Rank Fusion (k=60)...\")\n",
    "rrf_results = reciprocal_rank_fusion({\n",
    "    \"vector\": vec_results,\n",
    "    \"keyword\": kw_results\n",
    "}, k=60)\n",
    "\n",
    "# 3. Display Results\n",
    "df = pd.DataFrame(rrf_results)\n",
    "\n",
    "# Format 'ranks' column for better readability\n",
    "def format_ranks(ranks_dict):\n",
    "    return \", \".join([f\"{k}:#{v['rank']}\" for k, v in ranks_dict.items()])\n",
    "\n",
    "df['rank_info'] = df['ranks'].apply(format_ranks)\n",
    "\n",
    "columns = ['product_name', 'rrf_score', 'rank_info', 'review_text']\n",
    "print(df[columns].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "*   **RRF Score**: You should see that documents appearing in *both* top lists get a higher bump in the RRF score.\n",
    "*   **Rank Info**: Shows the rank of the document in each individual search method (e.g., `vector:#1, keyword:#3`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
